# -*- coding: utf-8 -*-
"""Series de tiempo 03/06/2025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fA1cirOUGQHLxLhueCVL1gyiPrWSjL-U
"""

!pip install statsmodels --upgrade

# Import required libraries
import pandas as pd
import numpy as np
from google.colab import files
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt

# Upload Excel files
print("Please upload COST Excel file")
cost_upload = files.upload()
cost_filename = list(cost_upload.keys())[0]
cost_df = pd.read_excel(cost_filename)

print("Please upload WMT Excel file")
wmt_upload = files.upload()
wmt_filename = list(wmt_upload.keys())[0]
wmt_df = pd.read_excel(wmt_filename)

# Print available columns
print("\nCOST DataFrame columns:", list(cost_df.columns))
print("WMT DataFrame columns:", list(wmt_df.columns))

# Ask user for the correct column name
close_column = input("Please enter the column name containing closing prices: ")

# Extract closing prices using user-specified column name
try:
    cost_close = cost_df[close_column]
    wmt_close = wmt_df[close_column]
except KeyError:
    print(f"Error: Column '{close_column}' not found in one or both DataFrames")
    print("Please check the column names and try again")
    raise

# Ensure both series have the same length
min_length = min(len(cost_close), len(wmt_close))
cost_close = cost_close[:min_length]
wmt_close = wmt_close[:min_length]

# Function for unit root tests
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")

    # ADF Test
    adf_result = adfuller(series)
    print("ADF Test:")
    print(f'ADF Statistic: {adf_result[0]:.4f}')
    print(f'p-value: {adf_result[1]:.4f}')
    print(f'Critical Values: {adf_result[4]}')

    # KPSS Test
    kpss_result = kpss(series)
    print("\nKPSS Test:")
    print(f'KPSS Statistic: {kpss_result[0]:.4f}')
    print(f'p-value: {kpss_result[1]:.4f}')
    print(f'Critical Values: {kpss_result[3]}')

# Perform unit root tests
unit_root_tests(cost_close, "COST")
unit_root_tests(wmt_close, "WMT")

# Difference the series if non-stationary
cost_diff = cost_close.diff().dropna()
wmt_diff = wmt_close.diff().dropna()

# Function to find best ARMA model (using ARIMA with d=0)
def find_best_arma(series, name, max_p=3, max_q=3):
    best_aic = float('inf')
    best_order = None

    for p in range(max_p + 1):
        for q in range(max_q + 1):
            try:
                model = ARIMA(series, order=(p, 0, q))
                results = model.fit()
                if results.aic < best_aic:
                    best_aic = results.aic
                    best_order = (p, 0, q)
            except:
                continue

    print(f"\nBest ARMA model for {name}:")
    print(f"Order: {best_order}")
    print(f"AIC: {best_aic:.2f}")

    best_model = ARIMA(series, order=best_order).fit()
    return best_model

# Fit ARMA models
cost_arma = find_best_arma(cost_diff, "COST")
wmt_arma = find_best_arma(wmt_diff, "WMT")

# Cointegration test
def cointegration_test(df):
    result = coint_johansen(df, det_order=0, k_ar_diff=1)
    print("\nJohansen Cointegration Test:")
    print(f"Trace statistic: {result.lr1}")
    print(f"Critical values (90%, 95%, 99%): {result.cvt}")

    for i in range(len(result.lr1)):
        if result.lr1[i] > result.cvt[i, 1]:  # 95% critical value
            print(f"r = {i}: Cointegration exists at 95% confidence level")
        else:
            print(f"r = {i}: No cointegration at 95% confidence level")

# Prepare data for cointegration
coint_df = pd.DataFrame({
    'COST': cost_close,
    'WMT': wmt_close
}).dropna()

# Run cointegration test
cointegration_test(coint_df)

# Plot the series
plt.figure(figsize=(12,6))
plt.plot(cost_close, label='COST')
plt.plot(wmt_close, label='WMT')
plt.title('COST vs WMT Closing Prices')
plt.legend()
plt.show()

# Plot the differenced series
plt.figure(figsize=(12,6))
plt.plot(cost_diff, label='COST Diff')
plt.plot(wmt_diff, label='WMT Diff')
plt.title('Differenced Series')
plt.legend()
plt.show()

# Import required libraries
import pandas as pd
import numpy as np
from google.colab import files
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt

# Upload Excel files
print("Please upload COST Excel file")
cost_upload = files.upload()
cost_filename = list(cost_upload.keys())[0]
cost_df = pd.read_excel(cost_filename)

print("Please upload WMT Excel file")
wmt_upload = files.upload()
wmt_filename = list(wmt_upload.keys())[0]
wmt_df = pd.read_excel(wmt_filename)

# Print available columns
print("\nCOST DataFrame columns:", list(cost_df.columns))
print("WMT DataFrame columns:", list(wmt_df.columns))

# Ask user for the correct column name
close_column = input("Please enter the column name containing closing prices: ")

# Extract closing prices using user-specified column name
try:
    cost_close = cost_df[close_column]
    wmt_close = wmt_df[close_column]
except KeyError:
    print(f"Error: Column '{close_column}' not found in one or both DataFrames")
    print("Please check the column names and try again")
    raise

# Ensure both series have the same length
min_length = min(len(cost_close), len(wmt_close))
cost_close = cost_close[:min_length]
wmt_close = wmt_close[:min_length]

# Function for unit root tests with interpretation
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")

    # ADF Test
    adf_result = adfuller(series)
    print("ADF Test:")
    print(f'ADF Statistic: {adf_result[0]:.4f}')
    print(f'p-value: {adf_result[1]:.4f}')
    print(f'Critical Values: {adf_result[4]}')
    print("Interpretation:")
    if adf_result[1] < 0.05:
        print(f"  - p-value < 0.05: Reject null hypothesis - {name} is stationary")
    else:
        print(f"  - p-value >= 0.05: Fail to reject null - {name} may be non-stationary")

    # KPSS Test
    kpss_result = kpss(series)
    print("\nKPSS Test:")
    print(f'KPSS Statistic: {kpss_result[0]:.4f}')
    print(f'p-value: {kpss_result[1]:.4f}')
    print(f'Critical Values: {kpss_result[3]}')
    print("Interpretation:")
    if kpss_result[1] < 0.05:
        print(f"  - p-value < 0.05: Reject null hypothesis - {name} is non-stationary")
    else:
        print(f"  - p-value >= 0.05: Fail to reject null - {name} may be stationary")

# Perform unit root tests
unit_root_tests(cost_close, "COST")
unit_root_tests(wmt_close, "WMT")

# Cointegration test with interpretation
def cointegration_test(df):
    result = coint_johansen(df, det_order=0, k_ar_diff=1)
    print("\nJohansen Cointegration Test:")
    print(f"Trace statistic: {result.lr1}")
    print(f"Critical values (90%, 95%, 99%): {result.cvt}")
    print("Interpretation:")
    for i in range(len(result.lr1)):
        if result.lr1[i] > result.cvt[i, 1]:
            print(f"  - r = {i}: Cointegration exists at 95% confidence level")
            print(f"    Trace statistic ({result.lr1[i]:.2f}) > 95% critical value ({result.cvt[i, 1]:.2f})")
        else:
            print(f"  - r = {i}: No cointegration at 95% confidence level")
            print(f"    Trace statistic ({result.lr1[i]:.2f}) <= 95% critical value ({result.cvt[i, 1]:.2f})")
    if result.lr1[0] > result.cvt[0, 1]:
        print("Conclusion: COST and WMT are cointegrated - they share a long-run equilibrium relationship")
    else:
        print("Conclusion: No evidence of cointegration between COST and WMT")

# Prepare data for cointegration
coint_df = pd.DataFrame({
    'COST': cost_close,
    'WMT': wmt_close
}).dropna()
cointegration_test(coint_df)

# Function to find best ARIMA model with interpretation
def find_best_arima(series, name, max_p=3, max_d=2, max_q=3):
    best_aic = float('inf')
    best_order = None

    for p in range(max_p + 1):
        for d in range(max_d + 1):
            for q in range(max_q + 1):
                try:
                    model = ARIMA(series, order=(p, d, q))
                    results = model.fit()
                    if results.aic < best_aic:
                        best_aic = results.aic
                        best_order = (p, d, q)
                except:
                    continue

    print(f"\nBest ARIMA model for {name}:")
    print(f"Order: {best_order}")
    print(f"AIC: {best_aic:.2f}")
    print("Interpretation:")
    print(f"  - p={best_order[0]}: {best_order[0]} autoregressive term(s)")
    print(f"  - d={best_order[1]}: {best_order[1]} difference(s) needed for stationarity")
    print(f"  - q={best_order[2]}: {best_order[2]} moving average term(s)")
    return best_order

# Find and fit best ARIMA models
cost_order = find_best_arima(cost_close, "COST")
wmt_order = find_best_arima(wmt_close, "WMT")

# Fit final ARIMA models
cost_model = ARIMA(cost_close, order=cost_order).fit()
wmt_model = ARIMA(wmt_close, order=wmt_order).fit()

# Forecast next 30 periods
forecast_steps = 30
cost_forecast = cost_model.forecast(steps=forecast_steps)
wmt_forecast = wmt_model.forecast(steps=forecast_steps)

# Create forecast index
last_index = len(cost_close) - 1
forecast_index = range(last_index + 1, last_index + 1 + forecast_steps)

# Plot original series with forecasts
plt.figure(figsize=(12,6))
plt.plot(cost_close, label='COST Historical')
plt.plot(forecast_index, cost_forecast, label='COST Forecast', color='red')
plt.plot(wmt_close, label='WMT Historical')
plt.plot(forecast_index, wmt_forecast, label='WMT Forecast', color='green')
plt.title('COST and WMT Closing Prices with Forecasts')
plt.legend()
plt.show()

# Detailed forecast plot with confidence intervals and interpretation
def plot_forecast(model, series, name, steps=30):
    forecast_obj = model.get_forecast(steps=steps)
    forecast = forecast_obj.predicted_mean
    conf_int = forecast_obj.conf_int()

    forecast_index = range(len(series), len(series) + steps)

    plt.figure(figsize=(12,6))
    plt.plot(series, label=f'{name} Historical')
    plt.plot(forecast_index, forecast, label='Forecast', color='red')
    plt.fill_between(forecast_index,
                    conf_int.iloc[:, 0],
                    conf_int.iloc[:, 1],
                    color='pink',
                    alpha=0.3,
                    label='95% Confidence Interval')
    plt.title(f'{name} Price Forecast')
    plt.legend()
    plt.show()

    # Forecast interpretation
    last_value = series.iloc[-1]
    mean_forecast = forecast.mean()
    print(f"\nForecast Interpretation for {name}:")
    print(f"Last observed value: {last_value:.2f}")
    print(f"Average forecast value: {mean_forecast:.2f}")
    print(f"Forecast change: {mean_forecast - last_value:.2f}")
    if mean_forecast > last_value:
        print("Trend: Upward forecast trend")
    elif mean_forecast < last_value:
        print("Trend: Downward forecast trend")
    else:
        print("Trend: Flat forecast trend")
    print(f"95% CI range at period {steps}: [{conf_int.iloc[-1, 0]:.2f}, {conf_int.iloc[-1, 1]:.2f}]")

# Generate detailed forecast plots and interpretations
plot_forecast(cost_model, cost_close, "COST")
plot_forecast(wmt_model, wmt_close, "WMT")

# Print forecast values
print("\nCOST Forecast Values (next 5 periods):")
print(cost_forecast[:5])
print("\nWMT Forecast Values (next 5 periods):")
print(wmt_forecast[:5])

import pandas as pd
import numpy as np
from google.colab import files
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt

# Dictionary to store DataFrames for each stock and time frame
data = {
    'TSLA': {'1min': None, '3min': None},
    'AAPL': {'1min': None, '3min': None},
    'NVDA': {'1min': None, '3min': None}
}

# Upload Excel files for TSLA, AAPL, NVDA (1-min and 3-min)
for stock in ['TSLA', 'AAPL', 'NVDA']:
    for timeframe in ['1min', '3min']:
        print(f"Please upload {stock} {timeframe} Excel file")
        uploaded = files.upload()
        filename = list(uploaded.keys())[0]
        data[stock][timeframe] = pd.read_excel(filename)

# Print available columns for verification
for stock in data:
    for timeframe in data[stock]:
        print(f"\n{stock} {timeframe} DataFrame columns:", list(data[stock][timeframe].columns))

# Ask user for the closing price column name
close_column = input("Please enter the column name containing closing prices: ")

# Extract closing prices and ensure same length
close_data = {}
min_length = float('inf')
for stock in data:
    for timeframe in data[stock]:
        try:
            close_data[f"{stock}_{timeframe}"] = data[stock][timeframe][close_column]
            min_length = min(min_length, len(close_data[f"{stock}_{timeframe}"]))
        except KeyError:
            print(f"Error: Column '{close_column}' not found in {stock} {timeframe}")
            raise

# Truncate all series to the same length
for key in close_data:
    close_data[key] = close_data[key][:min_length]

# Function for unit root tests with interpretation
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")

    # ADF Test
    adf_result = adfuller(series)
    print("ADF Test:")
    print(f'ADF Statistic: {adf_result[0]:.4f}')
    print(f'p-value: {adf_result[1]:.4f}')
    print(f'Critical Values: {adf_result[4]}')
    print("Interpretation:")
    if adf_result[1] < 0.05:
        print(f"  - p-value < 0.05: Reject null hypothesis - {name} is stationary")
    else:
        print(f"  - p-value >= 0.05: Fail to reject null - {name} may be non-stationary")

    # KPSS Test
    kpss_result = kpss(series, regression='c', nlags='auto')
    print("\nKPSS Test:")
    print(f'KPSS Statistic: {kpss_result[0]:.4f}')
    print(f'p-value: {kpss_result[1]:.4f}')
    print(f'Critical Values: {kpss_result[3]}')
    print("Interpretation:")
    if kpss_result[1] < 0.05:
        print(f"  - p-value < 0.05: Reject null hypothesis - {name} is non-stationary")
    else:
        print(f"  - p-value >= 0.05: Fail to reject null - {name} may be stationary")

# Perform unit root tests for all series
for key in close_data:
    unit_root_tests(close_data[key], key)

# Cointegration test for each timeframe
def cointegration_test(df, timeframe):
    result = coint_johansen(df, det_order=0, k_ar_diff=1)
    print(f"\nJohansen Cointegration Test ({timeframe}):")
    print(f"Trace statistic: {result.lr1}")
    print(f"Critical values (90%, 95%, 99%): {result.cvt}")
    print("Interpretation:")
    for i in range(len(result.lr1)):
        if result.lr1[i] > result.cvt[i, 1]:
            print(f"  - r = {i}: Cointegration exists at 95% confidence level")
            print(f"    Trace statistic ({result.lr1[i]:.2f}) > 95% critical value ({result.cvt[i, 1]:.2f})")
        else:
            print(f"  - r = {i}: No cointegration at 95% confidence level")
            print(f"    Trace statistic ({result.lr1[i]:.2f}) <= 95% critical value ({result.cvt[i, 1]:.2f})")
    if result.lr1[0] > result.cvt[0, 1]:
        print(f"Conclusion: TSLA, AAPL, and NVDA are cointegrated in {timeframe} - they share a long-run equilibrium relationship")
    else:
        print(f"Conclusion: No evidence of cointegration between TSLA, AAPL, and NVDA in {timeframe}")

# Prepare data for cointegration (1-min and 3-min separately)
for timeframe in ['1min', '3min']:
    coint_df = pd.DataFrame({
        'TSLA': close_data[f"TSLA_{timeframe}"],
        'AAPL': close_data[f"AAPL_{timeframe}"],
        'NVDA': close_data[f"NVDA_{timeframe}"]
    }).dropna()
    cointegration_test(coint_df, timeframe)

# Function to find best ARIMA model
def find_best_arima(series, name, max_p=3, max_d=2, max_q=3):
    best_aic = float('inf')
    best_order = None

    for p in range(max_p + 1):
        for d in range(max_d + 1):
            for q in range(max_q + 1):
                try:
                    model = ARIMA(series, order=(p, d, q))
                    results = model.fit()
                    if results.aic < best_aic:
                        best_aic = results.aic
                        best_order = (p, d, q)
                except:
                    continue

    print(f"\nBest ARIMA model for {name}:")
    print(f"Order: {best_order}")
    print(f"AIC: {best_aic:.2f}")
    print("Interpretation:")
    print(f"  - p={best_order[0]}: {best_order[0]} autoregressive term(s)")
    print(f"  - d={best_order[1]}: {best_order[1]} difference(s) needed for stationarity")
    print(f"  - q={best_order[2]}: {best_order[2]} moving average term(s)")
    return best_order

# Find and fit best ARIMA models for each series
arima_models = {}
for key in close_data:
    order = find_best_arima(close_data[key], key)
    arima_models[key] = ARIMA(close_data[key], order=order).fit()

# Forecast next 30 periods
forecast_steps = 30
forecasts = {}
for key in close_data:
    forecasts[key] = arima_models[key].forecast(steps=forecast_steps)

# Plot original series with forecasts
plt.figure(figsize=(12, 6))
for key in close_data:
    plt.plot(close_data[key], label=f'{key} Historical')
    forecast_index = range(len(close_data[key]), len(close_data[key]) + forecast_steps)
    plt.plot(forecast_index, forecasts[key], label=f'{key} Forecast')
plt.title('TSLA, AAPL, NVDA Closing Prices with Forecasts')
plt.legend()
plt.show()

# Detailed forecast plot with confidence intervals
def plot_forecast(model, series, name, steps=30):
    forecast_obj = model.get_forecast(steps=steps)
    forecast = forecast_obj.predicted_mean
    conf_int = forecast_obj.conf_int()

    forecast_index = range(len(series), len(series) + steps)

    plt.figure(figsize=(12, 6))
    plt.plot(series, label=f'{name} Historical')
    plt.plot(forecast_index, forecast, label='Forecast', color='red')
    plt.fill_between(forecast_index,
                    conf_int.iloc[:, 0],
                    conf_int.iloc[:, 1],
                    color='pink',
                    alpha=0.3,
                    label='95% Confidence Interval')
    plt.title(f'{name} Price Forecast')
    plt.legend()
    plt.show()

    # Forecast interpretation
    last_value = series.iloc[-1]
    mean_forecast = forecast.mean()
    print(f"\nForecast Interpretation for {name}:")
    print(f"Last observed value: {last_value:.2f}")
    print(f"Average forecast value: {mean_forecast:.2f}")
    print(f"Forecast change: {mean_forecast - last_value:.2f}")
    if mean_forecast > last_value:
        print("Trend: Upward forecast trend")
    elif mean_forecast < last_value:
        print("Trend: Downward forecast trend")
    else:
        print("Trend: Flat forecast trend")
    print(f"95% CI range at period {steps}: [{conf_int.iloc[-1, 0]:.2f}, {conf_int.iloc[-1, 1]:.2f}]")

# Generate detailed forecast plots and interpretations
for key in close_data:
    plot_forecast(arima_models[key], close_data[key], key)

# Print forecast values for first 5 periods
for key in forecasts:
    print(f"\n{key} Forecast Values (next 5 periods):")
    print(forecasts[key][:5])